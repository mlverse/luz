[{"path":"/LICENSE.html","id":"mit-license","dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 luz authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"/articles/custom-loop.html","id":"multiple-optimizers","dir":"Articles","previous_headings":"","what":"Multiple optimizers","title":"Custom loops with luz","text":"Suppose want experiment train first fully connected layer using learning rate 0.1 second one using learning rate 0.01. minimizing nn_cross_entropy_loss() first layer want add L1 regularization weights. order use luz implement two methods net module: set_optimizers: returns named list optimizers depending ctx. loss: computes loss depending selected optimizer. Let’s go code: Notice model optimizers initialized according set_optimizers() method return value. case, initializing optimizers using different model parameters learning rates. loss() method responsible computing loss backpropagated compute gradients update weights. loss() method can access ctx object contain opt_name field, describing optimizer currently used. Note function called optimizer training validation step. See help(\"ctx\") complete information context object. can finally setup fit module, however longer need specify optimizers loss functions. Now let’s re-implement model using slightly flexible approach consisting overriding training validation step.","code":"net <- nn_module(   \"Net\",   initialize = function() {     self$fc1 <- nn_linear(100, 50)     self$fc1 <- nn_linear(50, 10)   },   forward = function(x) {     x %>%        self$fc1() %>%        nnf_relu() %>%        self$fc2()   },   set_optimizers = function(lr_fc1 = 0.1, lr_fc2 = 0.01) {     list(       opt_fc1 = optim_adam(self$fc1$parameters, lr = lr_fc1),       opt_fc2 = optim_adam(self$fc2$parameters, lr = lr_fc2)     )   },   loss = function(input, target) {     pred <- ctx$model(input)        if (ctx$opt_name == \"opt_fc1\")        nnf_cross_entropy(pred, target) + torch_norm(self$fc1$weight, p = 1)     else if (ctx$opt_name == \"opt_fc2\")       nnf_cross_entropy(pred, target)   } ) fitted <- net %>%    setup(metrics = list(       luz_metric_accuracy   )) %>%    fit(train_dl, epochs = 10, valid_data = test_dl)"},{"path":"/articles/custom-loop.html","id":"fully-flexible-step","dir":"Articles","previous_headings":"","what":"Fully flexible step","title":"Custom loops with luz","text":"Instead implementing loss() method can implement step() method, allows us flexibly modify happens training validating batch dataset. now responsible updating weights stepping optimizers backpropagating loss. important things notice : step() method used training validation. need careful modify weights training. , can get complete information regarding context object using help(\"ctx\"). ctx$optimizers named list holding optimizer created set_optimizers() method called. need manually track losses saving saving named list ctx$loss. convention, use name optimizer refers . ’s good practice detach() saving reduce memory usage. Callbacks called inside default step() method like on_train_batch_after_pred, on_train_batch_after_loss , etc won’t automatically called. can still cal manually adding ctx$call_callbacks(\"<callback name>\") inside training step. See code fit_one_batch() valid_one_batch find callbacks won’t called.","code":"net <- nn_module(   \"Net\",   initialize = function() {     self$fc1 <- nn_linear(100, 50)     self$fc1 <- nn_linear(50, 10)   },   forward = function(x) {     x %>%        self$fc1() %>%        nnf_relu() %>%        self$fc2()   },   set_optimizers = function(lr_fc1 = 0.1, lr_fc2 = 0.01) {     list(       opt_fc1 = optim_adam(self$fc1$parameters, lr = lr_fc1),       opt_fc2 = optim_adam(self$fc2$parameters, lr = lr_fc2)     )   },   step = function() {     ctx$loss <- list()     for (opt_name in names(ctx$optimizers)) {            pred <- ctx$model(ctx$input)       opt <- ctx$optimizers[[opt_name]]       loss <- nnf_cross_entropy(pred, target)              if (opt_name == \"opt_fc1\") {         # we have L1 regularization in layer 1         loss <- nnf_cross_entropy(pred, target) +            torch_norm(self$fc1$weight, p = 1)       }                if (ctx$training) {         opt$zero_grad()         loss$backward()         opt$step()         }              ctx$loss[[opt_name]] <- loss$detach()     }   } )"},{"path":"/articles/custom-loop.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next steps","title":"Custom loops with luz","text":"article learned customize step() training loop using luz layered functionality. Luz also allows flexible modifications training loop described Accelerator vignette. now able follow examples marked ‘intermediate’ ‘advanced’ category examples gallery.","code":""},{"path":"/articles/get-started.html","id":"training-a-nn_module","dir":"Articles","previous_headings":"","what":"Training a nn_module","title":"Get started with Luz","text":"Luz tries reuse much possible existing structures Torch. example, model Luz defined identically define using raw Torch. example, definition feedforward CNN can used classify digits MNIST dataset. can now train model train_dl validate test_dl torch::dataloaders() : Let’s understand happens chunk code: setup function allows configure loss (objective) function optimizer use train model. Optionally can pass list metrics tracked training procedure. Note: loss function can function taking input target tensors returning scalar tensor value optimizer can core Torch optimizer custom ones created torch::optimizer() function. fit method take model specification provided setup() run training procedure using specified training validation torch::dataloaders() well number epochs. Note: reuse core Torch data structures, instead providing data loading functionality. returned object fitted contains trained model well record metrics losses produced training. can also used producing predictions evaluating trained model datasets. fitting, Luz use fastest possible accelerator, ie. CUDA capable GPU available used otherwise fallback CPU. also automatically moves data, optimizers models selected device don’t need handle manually - general error prone. create predictions trained model can use predict method:","code":"net <- nn_module(   \"Net\",   initialize = function() {     self$conv1 <- nn_conv2d(1, 32, 3, 1)     self$conv2 <- nn_conv2d(32, 64, 3, 1)     self$dropout1 <- nn_dropout2d(0.25)     self$dropout2 <- nn_dropout2d(0.5)     self$fc1 <- nn_linear(9216, 128)     self$fc2 <- nn_linear(128, 10)   },   forward = function(x) {     x <- self$conv1(x)     x <- nnf_relu(x)     x <- self$conv2(x)     x <- nnf_relu(x)     x <- nnf_max_pool2d(x, 2)     x <- self$dropout1(x)     x <- torch_flatten(x, start_dim = 2)     x <- self$fc1(x)     x <- nnf_relu(x)     x <- self$dropout2(x)     x <- self$fc2(x)     x   } ) fitted <- net %>%   setup(     loss = nn_cross_entropy_loss(),     optimizer = optim_adam,     metrics = list(       luz_metric_accuracy     )   ) %>%   fit(train_dl, epochs = 10, valid_data = test_dl) predictions <- predict(fitted, test_dl)"},{"path":"/articles/get-started.html","id":"the-training-loop","dir":"Articles","previous_headings":"","what":"The training loop","title":"Get started with Luz","text":"now general idea use fit function now ’s important overview ’s happening inside . pseudocode, ’s fit . fully detailed help build intuition:","code":"# -> Initialize objects: model, optimizers. # -> Select fitting device. # -> Move data, model, optimizers to the selected device. # -> Start training for (epoch in 1:epochs) {   # -> Training procedure   for (batch in train_dl) {     # -> Calculate model `forward` method.     # -> Calulate the loss     # -> Update weights     # -> Update metrics and tracking loss   }   # -> Validation procedure   for (batch in valid_dl) {     # -> Calculate model `forward` method.     # -> Calulate the loss     # -> Update metrics and tracking loss   } } # -> End training"},{"path":"/articles/get-started.html","id":"metrics","dir":"Articles","previous_headings":"","what":"Metrics","title":"Get started with Luz","text":"One important parts machine learning projects choosing evaluation metric. Luz allows tracking many different metrics training minimal code changes. order track metrics, need modify metrics parameter setup function: Luz provides implementations used metrics. metric available can always implement new one using luz_metric function. order implement new luz_metric need implement 3 methods: initialize: defines metric initial state. function called epoch training validation loops. update: updates metric internal state. function called every training validation step predictions obtained model target values obtained dataloader. compute: uses internal state compute metric values. function called whenever need obtain current metric value. Eg, ’s called every training step metrics displayed progress bar, called per epoch record ’s value progress bar displayed. Optionally, can implement abbrev field gives metric abbreviation used displaying metric information console tracking record. abbrev passed, class name used. Let’s take look implementation luz_metric_accuracy can see implement new one: Note: ’s good practice compute metric returns regular R values instead torch tensors parts luz expect .","code":"fitted <- net %>%   setup(     ...     metrics = list(       luz_metric_accuracy     )   ) %>%   fit(...) luz_metric_accuracy <- luz_metric(   # An abbreviation to be shown in progress bars, or    # when printing progress   abbrev = \"Acc\",    # Initial setup for the metric. Metrics are initialized   # every epoch, for both training and validation   initialize = function() {     self$correct <- 0     self$total <- 0   },   # Run at every training or validation step and updates   # the internal state. The update function takes `preds`   # and `target` as parameters.   update = function(preds, target) {     pred <- torch::torch_argmax(preds, dim = 2)     self$correct <- self$correct + (pred == target)$       to(dtype = torch::torch_float())$       sum()$       item()     self$total <- self$total + pred$numel()   },   # Use the internal state to query the metric value   compute = function() {     self$correct/self$total   } )"},{"path":"/articles/get-started.html","id":"customizing-with-callbacks","dir":"Articles","previous_headings":"","what":"Customizing with callbacks","title":"Get started with Luz","text":"Luz provides different ways customize training progress depending level control need training loop. fastest way ‘reusable’, sense can create training modification can used many different situations via callbacks. training loop Luz many breakpoints can call arbitrary R functions. functionality allows customize training process without modify general training logic. Luz implements 3 default callbacks occur every training procedure: train-eval callback: Set’s model train() eval() depending procedure training validation. metrics callback: evaluate metrics training validation process. progress callback: implements progress bar prints progress information training. can also implement custom callbacks modify act specifically training procedure. example: Let’s implement callback prints ‘Iteration n’ (n iteration number) every batch training set ‘Done’ epoch finished. task use luz_callback function: luz_callback() takes named list function argument name indicate moment callback called. instance on_train_batch_end() called every batch end training procedure on_epoch() end called end every epoch. returned value luz_callback() function initializes instance callback. Callbacks can initialization parameters, like name file want log results, case, can pass initialize method creating callback definition save parameters self object. example, callback message parameter printed end epoch. callback defined can passed fit function via callbacks parameter, eg: Callbacks can called many different positions training loop, including combinations . ’s overview possible callback breakpoints: Every step market on_* point training procedure available callbacks called. important part callbacks ctx (context) object. See help(\"ctx\") details. ctx object used luz share information training loop callbacks, model methods metrics. table describes information available ctx default. callbacks potentially modify attributes add new ones. Context attributes Attributes ctx can used produce desired behavior callbacks. time can find information context object using help(\"ctx\"). example, use ctx$iter attribute print iteration number training batch.","code":"print_callback <- luz_callback(   name = \"print_callback\",   initialize = function(message) {     self$message <- message   },   on_train_batch_end = function() {     cat(\"Iteration \", ctx$iter, \"\\n\")   },   on_epoch_end = function() {     cat(self$message, \"\\n\")   } ) fitted <- net %>%   setup(...) %>%   fit(..., callbacks = list(     print_callback(message = \"Done!\")   )) Start Fit    - on_fit_begin   Start Epoch Loop      - on_epoch_begin     Start Train        - on_train_begin       Start Batch Loop          - on_train_batch_begin           Start Default Training Step             - on_train_batch_after_pred             - on_train_batch_after_loss             - on_train_batch_before_backward             - on_train_batch_before_step             - on_train_batch_after_step           End Default Training Step:          - on_train_batch_end       End Batch Loop        - on_train_end     End Train     Start Valid        - on_valid_begin       Start Batch Loop          - on_valid_batch_begin           Start Default Validation Step             - on_valid_batch_after_pred             - on_valid_batch_after_loss           End Default Validation Step          - on_valid_batch_end       End Batch Loop        - on_valid_end     End Valid       - on_epoch_end   End Epoch Loop    - on_fit_end End Fit"},{"path":"/articles/get-started.html","id":"next-steps","dir":"Articles","previous_headings":"","what":"Next steps","title":"Get started with Luz","text":"article learned train first model using Luz basics customization using custom metrics callbacks. Luz also allows flexible modifications training loop described vignette(\"custom-loop\"). now able follow examples marked ‘basic’ category examples gallery.","code":""},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors","text":"Daniel Falbel. Author, maintainer, copyright holder. RStudio. Copyright holder.","code":""},{"path":"/index.html","id":"luz","dir":"","previous_headings":"","what":"Higher Level API for torch","title":"Higher Level API for torch","text":"luz higher level API torch providing abstractions allow much less verbose training loops. package early stage development. Don’t use anything meaningful yet. ’s heavily inspired higher level frameworks deep learning, cite : FastAI: heavily inspired FastAI library, specially Learner object callbacks API. Keras: also heavily inspired Keras, specially callback names, lightning module interface similar compile . PyTorch Lightning: idea luz_module subclass nn_module inspired LightningModule object lightning. HuggingFace Accelerate: internal device placement API heavily inspired Accelerate, much modest features. Currenly CPU Single GPU supported.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Higher Level API for torch","text":"Luz yet available CRAN. can install development version :","code":"remotes::install_github(\"mlverse/luz\")"},{"path":"/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Higher Level API for torch","text":"Luz let’s take Torch nn_module definition fit dataloader, handling boring parts like moving data devices, updating weights, showing progress bars tracking metrics. ’s example defining training Autoencoder MNIST dataset. selected parts code highlight Luz functionality. can find full example code . Now defined Autoencder architecture using torch::nn_module(), can fit using Luz:","code":"net <- nn_module(   \"Net\",   initialize = function() {     self$encoder <- nn_sequential(       nn_conv2d(1, 6, kernel_size=5),       nn_relu(),       nn_conv2d(6, 16, kernel_size=5),       nn_relu()     )     self$decoder <- nn_sequential(       nn_conv_transpose2d(16, 6, kernel_size = 5),       nn_relu(),       nn_conv_transpose2d(6, 1, kernel_size = 5),       nn_sigmoid()     )   },   forward = function(x) {     x %>%       self$encoder() %>%       self$decoder()   } ) fitted <- net %>%   setup(     loss = nn_mse_loss(),     optimizer = optim_adam   ) %>%   fit(train_dl, epochs = 1, valid_data = test_dl)"},{"path":"/reference/accelerator.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an accelerator — accelerator","title":"Create an accelerator — accelerator","text":"Create accelerator","code":""},{"path":"/reference/accelerator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an accelerator — accelerator","text":"","code":"accelerator(device_placement = TRUE, cpu = FALSE)"},{"path":"/reference/accelerator.html","id":"pkg-arg-device_placement","dir":"Reference","previous_headings":"","what":"device_placement (argument)","title":"Create an accelerator — accelerator","text":"device_placement (logical) whether accelerator object handle device placement. Default: TRUE","code":""},{"path":"/reference/accelerator.html","id":"pkg-arg-cpu","dir":"Reference","previous_headings":"","what":"cpu (argument)","title":"Create an accelerator — accelerator","text":"cpu (logical) whether training procedure run CPU.","code":""},{"path":"/reference/ctx.html","id":null,"dir":"Reference","previous_headings":"","what":"Context object — ctx","title":"Context object — ctx","text":"Context objects used luz share information model methods, metrics callbacks.","code":""},{"path":"/reference/ctx.html","id":"section-details","dir":"Reference","previous_headings":"","what":"Details","title":"Context object — ctx","text":"ctx object used luz share information training loop callbacks, model methods metrics. table describes information available ctx default. callbacks potentially modify attributes add new ones. Context attributes","code":""},{"path":"/reference/fit.luz_module_generator.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit a nn_module — fit.luz_module_generator","title":"Fit a nn_module — fit.luz_module_generator","text":"Fit nn_module","code":""},{"path":"/reference/fit.luz_module_generator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit a nn_module — fit.luz_module_generator","text":"","code":"# S3 method for luz_module_generator fit(   object,   data,   epochs = 10,   callbacks = NULL,   valid_data = NULL,   accelerator = NULL,   verbose = NULL,   ... )"},{"path":"/reference/fit.luz_module_generator.html","id":"pkg-arg-object","dir":"Reference","previous_headings":"","what":"object (argument)","title":"Fit a nn_module — fit.luz_module_generator","text":"object nn_module setup().","code":""},{"path":"/reference/fit.luz_module_generator.html","id":"pkg-arg-data","dir":"Reference","previous_headings":"","what":"data (argument)","title":"Fit a nn_module — fit.luz_module_generator","text":"data (dataloader) dataloader created torch::dataloader() used training model. dataloader must return list 2 items. first item used input module second used target loss function.","code":""},{"path":"/reference/fit.luz_module_generator.html","id":"pkg-arg-epochs","dir":"Reference","previous_headings":"","what":"epochs (argument)","title":"Fit a nn_module — fit.luz_module_generator","text":"epochs (int) number epochs training model.","code":""},{"path":"/reference/fit.luz_module_generator.html","id":"pkg-arg-callbacks","dir":"Reference","previous_headings":"","what":"callbacks (argument)","title":"Fit a nn_module — fit.luz_module_generator","text":"callbacks (list, optional) list callbacks defined luz_callback() called training procedure. callbacks luz_callback_metrics(), luz_callback_progress() luz_callback_train_valid() always added default.","code":""},{"path":"/reference/fit.luz_module_generator.html","id":"pkg-arg-valid_data","dir":"Reference","previous_headings":"","what":"valid_data (argument)","title":"Fit a nn_module — fit.luz_module_generator","text":"valid_data (dataloader, optional) dataloader created torch::dataloader() used validation procedure.","code":""},{"path":"/reference/fit.luz_module_generator.html","id":"pkg-arg-accelerator","dir":"Reference","previous_headings":"","what":"accelerator (argument)","title":"Fit a nn_module — fit.luz_module_generator","text":"accelerator (accelerator, optional) optional accelerator() object used configure device placement components like nn_modules, optimizers batches data.","code":""},{"path":"/reference/fit.luz_module_generator.html","id":"pkg-arg-verbose","dir":"Reference","previous_headings":"","what":"verbose (argument)","title":"Fit a nn_module — fit.luz_module_generator","text":"verbose (logical, optional) optional boolean value indicating fitting procedure emmit output console training. default, produce output interactive() TRUE, otherwise print console.","code":""},{"path":"/reference/fit.luz_module_generator.html","id":"pkg-arg-...","dir":"Reference","previous_headings":"","what":"... (argument)","title":"Fit a nn_module — fit.luz_module_generator","text":"... Currently unused,","code":""},{"path":"/reference/luz_callback.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a new callback — luz_callback","title":"Create a new callback — luz_callback","text":"Create new callback","code":""},{"path":"/reference/luz_callback.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a new callback — luz_callback","text":"","code":"luz_callback(   name = NULL,   ...,   private = NULL,   active = NULL,   parent_env = parent.frame(),   inherit = NULL )"},{"path":"/reference/luz_callback.html","id":"pkg-arg-name","dir":"Reference","previous_headings":"","what":"name (argument)","title":"Create a new callback — luz_callback","text":"name name callback","code":""},{"path":"/reference/luz_callback.html","id":"pkg-arg-...","dir":"Reference","previous_headings":"","what":"... (argument)","title":"Create a new callback — luz_callback","text":"... Public methods callback. name methods used know called. See details section.","code":""},{"path":"/reference/luz_callback.html","id":"pkg-arg-private","dir":"Reference","previous_headings":"","what":"private (argument)","title":"Create a new callback — luz_callback","text":"private optional list private members, can functions non-functions.","code":""},{"path":"/reference/luz_callback.html","id":"pkg-arg-active","dir":"Reference","previous_headings":"","what":"active (argument)","title":"Create a new callback — luz_callback","text":"active optional list active binding functions.","code":""},{"path":"/reference/luz_callback.html","id":"pkg-arg-parent_env","dir":"Reference","previous_headings":"","what":"parent_env (argument)","title":"Create a new callback — luz_callback","text":"parent_env environment use parent newly-created objects.","code":""},{"path":"/reference/luz_callback.html","id":"pkg-arg-inherit","dir":"Reference","previous_headings":"","what":"inherit (argument)","title":"Create a new callback — luz_callback","text":"inherit R6ClassGenerator object inherit ; words, superclass. captured unevaluated expression evaluated parent_env time object instantiated.","code":""},{"path":"/reference/luz_callback.html","id":"section-value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a new callback — luz_callback","text":"luz_callback can passed fit.luz_module_generator().","code":""},{"path":"/reference/luz_callback.html","id":"section-details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a new callback — luz_callback","text":"Let’s implement callback prints ‘Iteration n’ (n iteration number) every batch training set ‘Done’ epoch finished. task use luz_callback function:  luz_callback() takes named list function argument name indicate moment callback called. instance on_train_batch_end() called every batch end training procedure on_epoch() end called end every epoch. returned value luz_callback() function initializes instance callback. Callbacks can initialization parameters, like name file want log results, case, can pass initialize method creating callback definition save parameters self object. example, callback message parameter printed end epoch. callback defined can passed fit function via callbacks parameter, eg:  Callbacks can called many different positions training loop, including combinations . ’s overview possible callback breakpoints: Every step market on_* point training procedure available callbacks called. important part callbacks ctx (context) object. See help(\"ctx\") details.","code":"print_callback <- luz_callback(   name = \"print_callback\",   initialize = function(message) {     self$message <- message   },   on_train_batch_end = function() {     cat(\"Iteration \", ctx$iter, \"\\n\")   },   on_epoch_end = function() {     cat(self$message, \"\\n\")   } ) fitted <- net %>%   setup(...) %>%   fit(..., callbacks = list(     print_callback(message = \"Done!\")   )) Start Fit    - on_fit_begin   Start Epoch Loop      - on_epoch_begin     Start Train        - on_train_begin       Start Batch Loop          - on_train_batch_begin           Start Default Training Step             - on_train_batch_after_pred             - on_train_batch_after_loss             - on_train_batch_before_backward             - on_train_batch_before_step             - on_train_batch_after_step           End Default Training Step:          - on_train_batch_end       End Batch Loop        - on_train_end     End Train     Start Valid        - on_valid_begin       Start Batch Loop          - on_valid_batch_begin           Start Default Validation Step             - on_valid_batch_after_pred             - on_valid_batch_after_loss           End Default Validation Step          - on_valid_batch_end       End Batch Loop        - on_valid_end     End Valid       - on_epoch_end   End Epoch Loop    - on_fit_end End Fit"},{"path":"/reference/luz_callback_early_stopping.html","id":null,"dir":"Reference","previous_headings":"","what":"Early stopping callback — luz_callback_early_stopping","title":"Early stopping callback — luz_callback_early_stopping","text":"Stops training monitored metric stops improving","code":""},{"path":"/reference/luz_callback_early_stopping.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Early stopping callback — luz_callback_early_stopping","text":"","code":"luz_callback_early_stopping(   monitor = \"valid_loss\",   min_delta = 0,   patience = 0,   mode = \"min\",   baseline = NULL )"},{"path":"/reference/luz_callback_early_stopping.html","id":"pkg-arg-monitor","dir":"Reference","previous_headings":"","what":"monitor (argument)","title":"Early stopping callback — luz_callback_early_stopping","text":"monitor string format <set>_<metric> <set> can 'train' 'valid' <metric> can abbreviation metric tracking training. metric name case insensitive.","code":""},{"path":"/reference/luz_callback_early_stopping.html","id":"pkg-arg-min_delta","dir":"Reference","previous_headings":"","what":"min_delta (argument)","title":"Early stopping callback — luz_callback_early_stopping","text":"min_delta Minimum improvement reset patience counter.","code":""},{"path":"/reference/luz_callback_early_stopping.html","id":"pkg-arg-patience","dir":"Reference","previous_headings":"","what":"patience (argument)","title":"Early stopping callback — luz_callback_early_stopping","text":"patience Number epochs without improving stoping training.","code":""},{"path":"/reference/luz_callback_early_stopping.html","id":"pkg-arg-mode","dir":"Reference","previous_headings":"","what":"mode (argument)","title":"Early stopping callback — luz_callback_early_stopping","text":"mode Specifies direction considered improvement. default 'min' used. Can also 'max' (higher better) 'zero' (closer zero better).","code":""},{"path":"/reference/luz_callback_early_stopping.html","id":"pkg-arg-baseline","dir":"Reference","previous_headings":"","what":"baseline (argument)","title":"Early stopping callback — luz_callback_early_stopping","text":"baseline initial value used best seen value begining. Model stopm training better baseline value found first patience epochs.","code":""},{"path":"/reference/luz_callback_early_stopping.html","id":"section-value","dir":"Reference","previous_headings":"","what":"Value","title":"Early stopping callback — luz_callback_early_stopping","text":"luz_callback early stopping.","code":""},{"path":"/reference/luz_callback_early_stopping.html","id":"section-note","dir":"Reference","previous_headings":"","what":"Note","title":"Early stopping callback — luz_callback_early_stopping","text":"callback adds on_early_stopping callback can used call callbacks soon model stopped training. verbose=TRUE fit.luz_module_generator() message printed early stopping.","code":""},{"path":"/reference/luz_callback_lr_scheduler.html","id":null,"dir":"Reference","previous_headings":"","what":"Learning rate scheduler callback — luz_callback_lr_scheduler","title":"Learning rate scheduler callback — luz_callback_lr_scheduler","text":"Initializes runs torch::lr_scheduler()s.","code":""},{"path":"/reference/luz_callback_lr_scheduler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Learning rate scheduler callback — luz_callback_lr_scheduler","text":"","code":"luz_callback_lr_scheduler(   lr_scheduler,   ...,   call_on = \"on_epoch_end\",   opt_name = NULL )"},{"path":"/reference/luz_callback_lr_scheduler.html","id":"pkg-arg-lr_scheduler","dir":"Reference","previous_headings":"","what":"lr_scheduler (argument)","title":"Learning rate scheduler callback — luz_callback_lr_scheduler","text":"lr_scheduler torch::lr_scheduler() initialized optimizer ... parameters.","code":""},{"path":"/reference/luz_callback_lr_scheduler.html","id":"pkg-arg-...","dir":"Reference","previous_headings":"","what":"... (argument)","title":"Learning rate scheduler callback — luz_callback_lr_scheduler","text":"... Additional arguments passed lr_scheduler together optimizers.","code":""},{"path":"/reference/luz_callback_lr_scheduler.html","id":"pkg-arg-call_on","dir":"Reference","previous_headings":"","what":"call_on (argument)","title":"Learning rate scheduler callback — luz_callback_lr_scheduler","text":"call_on callback breakpoint scheduler$step() called. Default 'on_epoch_end'. See luz_callback() information.","code":""},{"path":"/reference/luz_callback_lr_scheduler.html","id":"pkg-arg-opt_name","dir":"Reference","previous_headings":"","what":"opt_name (argument)","title":"Learning rate scheduler callback — luz_callback_lr_scheduler","text":"opt_name name optimizer affected callback. match name given set_optimizers. module single optimizer, opt_name used.","code":""},{"path":"/reference/luz_callback_lr_scheduler.html","id":"section-value","dir":"Reference","previous_headings":"","what":"Value","title":"Learning rate scheduler callback — luz_callback_lr_scheduler","text":"luz_callback() generator.","code":""},{"path":"/reference/luz_callback_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Metrics callback — luz_callback_metrics","title":"Metrics callback — luz_callback_metrics","text":"Tracks metrics passed setup() training validation.","code":""},{"path":"/reference/luz_callback_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Metrics callback — luz_callback_metrics","text":"","code":"luz_callback_metrics()"},{"path":"/reference/luz_callback_metrics.html","id":"section-details","dir":"Reference","previous_headings":"","what":"Details","title":"Metrics callback — luz_callback_metrics","text":"callback takes care 2 ctx attributes: ctx$metrics: stores metrics objects initialized epoch, update()d compute()d every batch. rarely need work metrics. ctx$records$metrics: Stores metrics per training/validation epoch. structure similar ctx$losses.","code":""},{"path":"/reference/luz_callback_metrics.html","id":"section-note","dir":"Reference","previous_headings":"","what":"Note","title":"Metrics callback — luz_callback_metrics","text":"general need explicitly use metrics callback used default fit.luz_module_generator().","code":""},{"path":"/reference/luz_callback_model_checkpoint.html","id":null,"dir":"Reference","previous_headings":"","what":"Checkpoints model weights — luz_callback_model_checkpoint","title":"Checkpoints model weights — luz_callback_model_checkpoint","text":"saves checkpoints model according specified metric behavior.","code":""},{"path":"/reference/luz_callback_model_checkpoint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Checkpoints model weights — luz_callback_model_checkpoint","text":"","code":"luz_callback_model_checkpoint(   path,   monitor = \"valid_loss\",   save_best_only = FALSE,   mode = \"min\",   min_delta = 0 )"},{"path":"/reference/luz_callback_model_checkpoint.html","id":"pkg-arg-path","dir":"Reference","previous_headings":"","what":"path (argument)","title":"Checkpoints model weights — luz_callback_model_checkpoint","text":"path Path save model disk. path interpolated glue, can use attribute within ctx using '{ctx$epoch}'. Specially epoch monitor quantities already environment. specified path path directory (ends / \\), models saved name given epoch-{epoch:02d}-{self$monitor}-{monitor:.3f}.pt. See examples. can use sprintf() quickly format quantities, example:'{epoch:02d}'.","code":""},{"path":"/reference/luz_callback_model_checkpoint.html","id":"pkg-arg-monitor","dir":"Reference","previous_headings":"","what":"monitor (argument)","title":"Checkpoints model weights — luz_callback_model_checkpoint","text":"monitor string format <set>_<metric> <set> can 'train' 'valid' <metric> can abbreviation metric tracking training. metric name case insensitive.","code":""},{"path":"/reference/luz_callback_model_checkpoint.html","id":"pkg-arg-save_best_only","dir":"Reference","previous_headings":"","what":"save_best_only (argument)","title":"Checkpoints model weights — luz_callback_model_checkpoint","text":"save_best_only TRUE models saved improvement previously saved model.","code":""},{"path":"/reference/luz_callback_model_checkpoint.html","id":"pkg-arg-mode","dir":"Reference","previous_headings":"","what":"mode (argument)","title":"Checkpoints model weights — luz_callback_model_checkpoint","text":"mode Specifies direction considered improvement. default 'min' used. Can also 'max' (higher better) 'zero' (closer zero better).","code":""},{"path":"/reference/luz_callback_model_checkpoint.html","id":"pkg-arg-min_delta","dir":"Reference","previous_headings":"","what":"min_delta (argument)","title":"Checkpoints model weights — luz_callback_model_checkpoint","text":"min_delta Minimum difference consider improvement. used save_best_only=TRUE.","code":""},{"path":"/reference/luz_callback_model_checkpoint.html","id":"section-note","dir":"Reference","previous_headings":"","what":"Note","title":"Checkpoints model weights — luz_callback_model_checkpoint","text":"mode min_delta used save_best_only=TRUE. save_best_only overwrite saved models path parameter differentiate epochs.","code":""},{"path":"/reference/luz_callback_progress.html","id":null,"dir":"Reference","previous_headings":"","what":"Progress callback — luz_callback_progress","title":"Progress callback — luz_callback_progress","text":"Responsible printing progress training.","code":""},{"path":"/reference/luz_callback_progress.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Progress callback — luz_callback_progress","text":"","code":"luz_callback_progress()"},{"path":"/reference/luz_callback_progress.html","id":"section-note","dir":"Reference","previous_headings":"","what":"Note","title":"Progress callback — luz_callback_progress","text":"general need use callback always included default fit.luz_module_generator(). Printing can disabled passing verbose=FALSE fit.luz_module_generator().","code":""},{"path":"/reference/luz_callback_train_valid.html","id":null,"dir":"Reference","previous_headings":"","what":"Train-eval callback — luz_callback_train_valid","title":"Train-eval callback — luz_callback_train_valid","text":"Switches important flags training evaluation modes.","code":""},{"path":"/reference/luz_callback_train_valid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Train-eval callback — luz_callback_train_valid","text":"","code":"luz_callback_train_valid()"},{"path":"/reference/luz_callback_train_valid.html","id":"section-details","dir":"Reference","previous_headings":"","what":"Details","title":"Train-eval callback — luz_callback_train_valid","text":"takes care three ctx attributes: ctx$model: Responsible calling ctx$model$train() ctx$model$eval(), appropriate. ctx$training: Sets flag TRUE training FALSE validation mode. ctx$loss: Resets loss attribute list() finished training/ validating.","code":""},{"path":"/reference/luz_callback_train_valid.html","id":"section-note","dir":"Reference","previous_headings":"","what":"Note","title":"Train-eval callback — luz_callback_train_valid","text":"general need explicitly use metrics callback used default fit.luz_module_generator().","code":""},{"path":"/reference/luz_load.html","id":null,"dir":"Reference","previous_headings":"","what":"Load trained model — luz_load","title":"Load trained model — luz_load","text":"Loads fitted model. See documentation luz_save().","code":""},{"path":"/reference/luz_load.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load trained model — luz_load","text":"","code":"luz_load(path)"},{"path":"/reference/luz_load.html","id":"pkg-arg-path","dir":"Reference","previous_headings":"","what":"path (argument)","title":"Load trained model — luz_load","text":"path path file system save object.","code":""},{"path":"/reference/luz_load_model_weights.html","id":null,"dir":"Reference","previous_headings":"","what":"Loads model weights into a fitted object. — luz_load_model_weights","title":"Loads model weights into a fitted object. — luz_load_model_weights","text":"can useful saved model checkpoints training want reload best checkpoint end.","code":""},{"path":"/reference/luz_load_model_weights.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Loads model weights into a fitted object. — luz_load_model_weights","text":"","code":"luz_load_model_weights(obj, path)  luz_save_model_weights(obj, path)"},{"path":"/reference/luz_load_model_weights.html","id":"pkg-arg-obj","dir":"Reference","previous_headings":"","what":"obj (argument)","title":"Loads model weights into a fitted object. — luz_load_model_weights","text":"obj luz object want copy new weights.","code":""},{"path":"/reference/luz_load_model_weights.html","id":"pkg-arg-path","dir":"Reference","previous_headings":"","what":"path (argument)","title":"Loads model weights into a fitted object. — luz_load_model_weights","text":"path path saved model disk.","code":""},{"path":"/reference/luz_load_model_weights.html","id":"section-value","dir":"Reference","previous_headings":"","what":"Value","title":"Loads model weights into a fitted object. — luz_load_model_weights","text":"Returns NULL invisibly.","code":""},{"path":"/reference/luz_load_model_weights.html","id":"section-warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Loads model weights into a fitted object. — luz_load_model_weights","text":"luz_save_model_weights operates inplace, ie modifies model object contain new weights.","code":""},{"path":"/reference/luz_metric.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a new luz metric — luz_metric","title":"Creates a new luz metric — luz_metric","text":"Creates new luz metric","code":""},{"path":"/reference/luz_metric.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a new luz metric — luz_metric","text":"","code":"luz_metric(   name = NULL,   ...,   private = NULL,   active = NULL,   parent_env = parent.frame(),   inherit = NULL )"},{"path":"/reference/luz_metric.html","id":"pkg-arg-name","dir":"Reference","previous_headings":"","what":"name (argument)","title":"Creates a new luz metric — luz_metric","text":"name string naming new metric.","code":""},{"path":"/reference/luz_metric.html","id":"pkg-arg-...","dir":"Reference","previous_headings":"","what":"... (argument)","title":"Creates a new luz metric — luz_metric","text":"... named list public methods. implement least initialize, update compute. See details section information.","code":""},{"path":"/reference/luz_metric.html","id":"pkg-arg-private","dir":"Reference","previous_headings":"","what":"private (argument)","title":"Creates a new luz metric — luz_metric","text":"private optional list private members, can functions non-functions.","code":""},{"path":"/reference/luz_metric.html","id":"pkg-arg-active","dir":"Reference","previous_headings":"","what":"active (argument)","title":"Creates a new luz metric — luz_metric","text":"active optional list active binding functions.","code":""},{"path":"/reference/luz_metric.html","id":"pkg-arg-parent_env","dir":"Reference","previous_headings":"","what":"parent_env (argument)","title":"Creates a new luz metric — luz_metric","text":"parent_env environment use parent newly-created objects.","code":""},{"path":"/reference/luz_metric.html","id":"pkg-arg-inherit","dir":"Reference","previous_headings":"","what":"inherit (argument)","title":"Creates a new luz metric — luz_metric","text":"inherit R6ClassGenerator object inherit ; words, superclass. captured unevaluated expression evaluated parent_env time object instantiated.","code":""},{"path":"/reference/luz_metric.html","id":"section-value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a new luz metric — luz_metric","text":"Returns new Luz metric.","code":""},{"path":"/reference/luz_metric.html","id":"section-details","dir":"Reference","previous_headings":"","what":"Details","title":"Creates a new luz metric — luz_metric","text":"order implement new luz_metric need implement 3 methods: initialize: defines metric initial state. function called epoch training validation loops. update: updates metric internal state. function called every training validation step predictions obtained model target values obtained dataloader. compute: uses internal state compute metric values. function called whenever need obtain current metric value. Eg, ’s called every training step metrics displayed progress bar, called per epoch record ’s value progress bar displayed. Optionally, can implement abbrev field gives metric abbreviation used displaying metric information console tracking record. abbrev passed, class name used. Let’s take look implementation luz_metric_accuracy can see implement new one:  Note: ’s good practice compute metric returns regular R values instead torch tensors parts luz expect .","code":"luz_metric_accuracy <- luz_metric(   # An abbreviation to be shown in progress bars, or    # when printing progress   abbrev = \"Acc\",    # Initial setup for the metric. Metrics are initialized   # every epoch, for both training and validation   initialize = function() {     self$correct <- 0     self$total <- 0   },   # Run at every training or validation step and updates   # the internal state. The update function takes `preds`   # and `target` as parameters.   update = function(preds, target) {     pred <- torch::torch_argmax(preds, dim = 2)     self$correct <- self$correct + (pred == target)$       to(dtype = torch::torch_float())$       sum()$       item()     self$total <- self$total + pred$numel()   },   # Use the internal state to query the metric value   compute = function() {     self$correct/self$total   } )"},{"path":"/reference/luz_metric_accuracy.html","id":null,"dir":"Reference","previous_headings":"","what":"Accuracy — luz_metric_accuracy","title":"Accuracy — luz_metric_accuracy","text":"Computes accuracy multi-class classification problems.","code":""},{"path":"/reference/luz_metric_accuracy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Accuracy — luz_metric_accuracy","text":"","code":"luz_metric_accuracy()"},{"path":"/reference/luz_metric_accuracy.html","id":"section-details","dir":"Reference","previous_headings":"","what":"Details","title":"Accuracy — luz_metric_accuracy","text":"metric expects take logits probabilities every update. take columnwise argmax compare target.","code":""},{"path":"/reference/luz_metric_binary_accuracy.html","id":null,"dir":"Reference","previous_headings":"","what":"Binary accuracy — luz_metric_binary_accuracy","title":"Binary accuracy — luz_metric_binary_accuracy","text":"Computes accuracy binary classification problems model returns probabilities. Commonly used loss torch::nn_bce_loss().","code":""},{"path":"/reference/luz_metric_binary_accuracy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binary accuracy — luz_metric_binary_accuracy","text":"","code":"luz_metric_binary_accuracy(threshold = 0.5)"},{"path":"/reference/luz_metric_binary_accuracy.html","id":"pkg-arg-threshold","dir":"Reference","previous_headings":"","what":"threshold (argument)","title":"Binary accuracy — luz_metric_binary_accuracy","text":"threshold value used classifiy observations 0 1.","code":""},{"path":"/reference/luz_metric_binary_accuracy_with_logits.html","id":null,"dir":"Reference","previous_headings":"","what":"Binary accuracy with logits — luz_metric_binary_accuracy_with_logits","title":"Binary accuracy with logits — luz_metric_binary_accuracy_with_logits","text":"Computes accuracy binary classification problems model return logits. Commonly used together torch::nn_bce_with_logits_loss().","code":""},{"path":"/reference/luz_metric_binary_accuracy_with_logits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Binary accuracy with logits — luz_metric_binary_accuracy_with_logits","text":"","code":"luz_metric_binary_accuracy_with_logits(threshold = 0.5)"},{"path":"/reference/luz_metric_binary_accuracy_with_logits.html","id":"pkg-arg-threshold","dir":"Reference","previous_headings":"","what":"threshold (argument)","title":"Binary accuracy with logits — luz_metric_binary_accuracy_with_logits","text":"threshold value used classifiy observations 0 1.","code":""},{"path":"/reference/luz_metric_binary_accuracy_with_logits.html","id":"section-details","dir":"Reference","previous_headings":"","what":"Details","title":"Binary accuracy with logits — luz_metric_binary_accuracy_with_logits","text":"Probabilities generated using torch::nnf_sigmoid() threshold used classify 0 1.","code":""},{"path":"/reference/luz_metric_mae.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean absolute error — luz_metric_mae","title":"Mean absolute error — luz_metric_mae","text":"Computes mean absolute error.","code":""},{"path":"/reference/luz_metric_mae.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean absolute error — luz_metric_mae","text":"","code":"luz_metric_mae()"},{"path":"/reference/luz_metric_mse.html","id":null,"dir":"Reference","previous_headings":"","what":"Mean squared error — luz_metric_mse","title":"Mean squared error — luz_metric_mse","text":"Computes mean squared error","code":""},{"path":"/reference/luz_metric_mse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Mean squared error — luz_metric_mse","text":"","code":"luz_metric_mse()"},{"path":"/reference/luz_metric_mse.html","id":"section-value","dir":"Reference","previous_headings":"","what":"Value","title":"Mean squared error — luz_metric_mse","text":"luz_metric object.","code":""},{"path":"/reference/luz_metric_rmse.html","id":null,"dir":"Reference","previous_headings":"","what":"Root mean squared error — luz_metric_rmse","title":"Root mean squared error — luz_metric_rmse","text":"Computes root mean squared error.","code":""},{"path":"/reference/luz_metric_rmse.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Root mean squared error — luz_metric_rmse","text":"","code":"luz_metric_rmse()"},{"path":"/reference/luz_save.html","id":null,"dir":"Reference","previous_headings":"","what":"Saves luz objects to disk — luz_save","title":"Saves luz objects to disk — luz_save","text":"Allows saving luz fitted models disk. Objects can loaded back luz_load().","code":""},{"path":"/reference/luz_save.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Saves luz objects to disk — luz_save","text":"","code":"luz_save(obj, path, ...)"},{"path":"/reference/luz_save.html","id":"pkg-arg-obj","dir":"Reference","previous_headings":"","what":"obj (argument)","title":"Saves luz objects to disk — luz_save","text":"obj object class 'luz_module_fitted' returned fit.luz_module_generator().","code":""},{"path":"/reference/luz_save.html","id":"pkg-arg-path","dir":"Reference","previous_headings":"","what":"path (argument)","title":"Saves luz objects to disk — luz_save","text":"path path file system save object.","code":""},{"path":"/reference/luz_save.html","id":"pkg-arg-...","dir":"Reference","previous_headings":"","what":"... (argument)","title":"Saves luz objects to disk — luz_save","text":"... currently unused.","code":""},{"path":"/reference/luz_save.html","id":"section-note","dir":"Reference","previous_headings":"","what":"Note","title":"Saves luz objects to disk — luz_save","text":"Objects saved plain .rds files obj$model serialized torch_save saving .","code":""},{"path":"/reference/luz_save.html","id":"section-warning","dir":"Reference","previous_headings":"","what":"Warning","title":"Saves luz objects to disk — luz_save","text":"ctx naively serialized. Ie, use saveRDS() serialize . expect luz_save work correctly unserializable objects ctx like torch_tensors external pointers general.","code":""},{"path":"/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. generics fit","code":""},{"path":"/reference/set_hparams.html","id":null,"dir":"Reference","previous_headings":"","what":"Set hyper-parameter of a module — set_hparams","title":"Set hyper-parameter of a module — set_hparams","text":"function used define hyper-parameters calling fit luz_modules.","code":""},{"path":"/reference/set_hparams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set hyper-parameter of a module — set_hparams","text":"","code":"set_hparams(module, ...)"},{"path":"/reference/set_hparams.html","id":"pkg-arg-module","dir":"Reference","previous_headings":"","what":"module (argument)","title":"Set hyper-parameter of a module — set_hparams","text":"module nn_module setup().","code":""},{"path":"/reference/set_hparams.html","id":"pkg-arg-...","dir":"Reference","previous_headings":"","what":"... (argument)","title":"Set hyper-parameter of a module — set_hparams","text":"... parameters set used initialize nn_module, ie passed unchanged initialize method base nn_module.","code":""},{"path":"/reference/set_opt_hparams.html","id":null,"dir":"Reference","previous_headings":"","what":"Set optimizer hyper-parameters — set_opt_hparams","title":"Set optimizer hyper-parameters — set_opt_hparams","text":"function used define hyper-parameters optimizer initialization method.","code":""},{"path":"/reference/set_opt_hparams.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set optimizer hyper-parameters — set_opt_hparams","text":"","code":"set_opt_hparams(module, ...)"},{"path":"/reference/set_opt_hparams.html","id":"pkg-arg-module","dir":"Reference","previous_headings":"","what":"module (argument)","title":"Set optimizer hyper-parameters — set_opt_hparams","text":"module nn_module setup().","code":""},{"path":"/reference/set_opt_hparams.html","id":"pkg-arg-...","dir":"Reference","previous_headings":"","what":"... (argument)","title":"Set optimizer hyper-parameters — set_opt_hparams","text":"... parameters passed used initialize optimizers. example, optimizer optim_adam pass lr=0.1, optim_adam function called optim_adam(parameters, lr=0.1) fitting model.","code":""},{"path":"/reference/setup.html","id":null,"dir":"Reference","previous_headings":"","what":"Set's up a nn_module to use with luz — setup","title":"Set's up a nn_module to use with luz — setup","text":"setup function used set important attributes method nn_modules used Luz.","code":""},{"path":"/reference/setup.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set's up a nn_module to use with luz — setup","text":"","code":"setup(module, loss = NULL, optimizer = NULL, metrics = NULL)"},{"path":"/reference/setup.html","id":"pkg-arg-module","dir":"Reference","previous_headings":"","what":"module (argument)","title":"Set's up a nn_module to use with luz — setup","text":"module (nn_module) nn_module want set .","code":""},{"path":"/reference/setup.html","id":"pkg-arg-loss","dir":"Reference","previous_headings":"","what":"loss (argument)","title":"Set's up a nn_module to use with luz — setup","text":"loss (function, optional) optional function signature function(input, target). requires nn_module implement method called loss.","code":""},{"path":"/reference/setup.html","id":"pkg-arg-optimizer","dir":"Reference","previous_headings":"","what":"optimizer (argument)","title":"Set's up a nn_module to use with luz — setup","text":"optimizer (torch_optimizer, optional) function signature function(parameters, ...) used initialize optimizer given model parameters.","code":""},{"path":"/reference/setup.html","id":"pkg-arg-metrics","dir":"Reference","previous_headings":"","what":"metrics (argument)","title":"Set's up a nn_module to use with luz — setup","text":"metrics (list, optional) list metrics tracked training procedure.","code":""},{"path":"/reference/setup.html","id":"section-details","dir":"Reference","previous_headings":"","what":"Details","title":"Set's up a nn_module to use with luz — setup","text":"makes sure module necessary ingredients order fitted.","code":""}]
