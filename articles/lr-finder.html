<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Using the learning rate finder • luz</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Using the learning rate finder">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">luz</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.5.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><h6 class="dropdown-header" data-toc-skip>Using luz</h6></li>
    <li><a class="dropdown-item" href="../articles/get-started.html">Get started</a></li>
    <li><a class="dropdown-item" href="../articles/custom-loop.html">Custom loops</a></li>
    <li><a class="dropdown-item" href="../articles/accelerator.html">Accelerator API</a></li>
    <li><h6 class="dropdown-header" data-toc-skip>Guides</h6></li>
    <li><a class="dropdown-item" href="../articles/lr-finder.html">Using the lr_finder</a></li>
    <li><a class="dropdown-item" href="../articles/checkpoints.html">Checkpoints models</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../articles/examples/index.html">Examples</a></li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/mlverse/luz/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Using the learning rate finder</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/mlverse/luz/blob/main/vignettes/articles/lr-finder.Rmd" class="external-link"><code>vignettes/articles/lr-finder.Rmd</code></a></small>
      <div class="d-none name"><code>lr-finder.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://mlverse.github.io/luz/">luz</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://torch.mlverse.org/docs" class="external-link">torch</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://torchvision.mlverse.org" class="external-link">torchvision</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span></span>
<span><span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://torch.mlverse.org/docs/reference/torch_manual_seed.html" class="external-link">torch_manual_seed</a></span><span class="op">(</span><span class="fl">1703</span><span class="op">)</span></span></code></pre></div>
<p>In this article we discuss how to find a good learning rate for your
model. Finding a good learning rate is essential to be able to fit your
model. If it’s too low, you will need too many iterations for your loss
to converge, and that might be impractical if your model takes too long
to run. If it’s too high, the loss can explode and you might never be
able to minimize the loss.</p>
<p>The learning rate can be considered another hyperparameter of your
model that needs to be tuned but, there are techniques that allow you to
select a good learning rate for your model without having to use the
costly strategy of fitting many models with different learning rates and
then choosing the one with better results.</p>
<p>This <a href="https://arxiv.org/abs/1506.01186" class="external-link">article</a> by Leslie
Smith that became popular once their approach had been implemented in
the popular FastAI framework, proposes that we should start with a very
small learning rate and slowly increase it until we reach a high
learning rate. At each iteration we record the loss value and in the end
we plot it against the learning rate. We can then use these results to
decide on a good learning rate. That’s what <code>lr_finder</code> does,
and we will show how to use it.</p>
<p>First let’s download and prepare the MNIST dataset:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">dir</span> <span class="op">&lt;-</span> <span class="st">"~/Downloads/mnist"</span> <span class="co"># caching directory</span></span>
<span></span>
<span><span class="va">train_ds</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://torchvision.mlverse.org/reference/mnist_dataset.html" class="external-link">mnist_dataset</a></span><span class="op">(</span></span>
<span>  <span class="va">dir</span>,</span>
<span>  download <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  transform <span class="op">=</span> <span class="va">transform_to_tensor</span></span>
<span><span class="op">)</span></span>
<span><span class="co">#&gt; Dataset <span style="color: #0000BB;">&lt;mnist&gt;</span> (~<span style="font-style: italic;">12 MB</span>) will be downloaded and processed if not already</span></span>
<span><span class="co">#&gt; available.</span></span>
<span><span class="co">#&gt; Downloading <span style="color: #0000BB;">&lt;mnist&gt;</span> ...</span></span>
<span><span class="co">#&gt; Processing <span style="color: #0000BB;">&lt;mnist&gt;</span>...</span></span>
<span><span class="co">#&gt; Dataset <span style="color: #0000BB;">&lt;mnist&gt;</span> downloaded and extracted successfully.</span></span>
<span><span class="co">#&gt; Dataset <span style="color: #0000BB;">&lt;mnist&gt;</span> loaded with 60000 images.</span></span></code></pre></div>
<p>We can now define our model. We are going to use a small,
straightforward CNN in the LeNet style.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">net</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://torch.mlverse.org/docs/reference/nn_module.html" class="external-link">nn_module</a></span><span class="op">(</span></span>
<span>  <span class="st">"net"</span>,</span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">features</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://torch.mlverse.org/docs/reference/nn_sequential.html" class="external-link">nn_sequential</a></span><span class="op">(</span></span>
<span>      <span class="fu"><a href="https://torch.mlverse.org/docs/reference/nn_conv2d.html" class="external-link">nn_conv2d</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">32</span>, <span class="fl">3</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>      <span class="fu"><a href="https://torch.mlverse.org/docs/reference/nn_relu.html" class="external-link">nn_relu</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>      <span class="fu"><a href="https://torch.mlverse.org/docs/reference/nn_max_pool2d.html" class="external-link">nn_max_pool2d</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span>,</span>
<span>      <span class="fu"><a href="https://torch.mlverse.org/docs/reference/nn_conv2d.html" class="external-link">nn_conv2d</a></span><span class="op">(</span><span class="fl">32</span>, <span class="fl">64</span>, <span class="fl">3</span>, <span class="fl">1</span><span class="op">)</span>,</span>
<span>      <span class="fu"><a href="https://torch.mlverse.org/docs/reference/nn_relu.html" class="external-link">nn_relu</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>      <span class="fu"><a href="https://torch.mlverse.org/docs/reference/nn_max_pool2d.html" class="external-link">nn_max_pool2d</a></span><span class="op">(</span><span class="fl">2</span><span class="op">)</span>,</span>
<span>      <span class="fu"><a href="https://torch.mlverse.org/docs/reference/nn_dropout.html" class="external-link">nn_dropout</a></span><span class="op">(</span><span class="fl">0.1</span><span class="op">)</span>,</span>
<span>      <span class="fu"><a href="https://torch.mlverse.org/docs/reference/nn_flatten.html" class="external-link">nn_flatten</a></span><span class="op">(</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">classifier</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://torch.mlverse.org/docs/reference/nn_sequential.html" class="external-link">nn_sequential</a></span><span class="op">(</span></span>
<span>      <span class="fu"><a href="https://torch.mlverse.org/docs/reference/nn_linear.html" class="external-link">nn_linear</a></span><span class="op">(</span><span class="fl">1600</span>, <span class="fl">128</span><span class="op">)</span>,</span>
<span>      <span class="fu"><a href="https://torch.mlverse.org/docs/reference/nn_dropout.html" class="external-link">nn_dropout</a></span><span class="op">(</span><span class="fl">0.1</span><span class="op">)</span>,</span>
<span>      <span class="fu"><a href="https://torch.mlverse.org/docs/reference/nn_linear.html" class="external-link">nn_linear</a></span><span class="op">(</span><span class="fl">128</span>, <span class="fl">10</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  forward <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">x</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> </span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">features</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> </span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">classifier</span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>We can now use the <code>lr_finder</code> function to record the loss
with different learning rates. It’s important to use the learning rate
finder with all other hyperparameters of the model fixed because they
can influence the choice of the learning rate. For example, depending on
the batch size, you might want to choose different learning rates.</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="va">net</span> <span class="op"><a href="../reference/pipe.html">%&gt;%</a></span> <span class="fu"><a href="../reference/setup.html">setup</a></span><span class="op">(</span></span>
<span>  loss <span class="op">=</span> <span class="fu">torch</span><span class="fu">::</span><span class="fu"><a href="https://torch.mlverse.org/docs/reference/nn_cross_entropy_loss.html" class="external-link">nn_cross_entropy_loss</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  optimizer <span class="op">=</span> <span class="fu">torch</span><span class="fu">::</span><span class="va"><a href="https://torch.mlverse.org/docs/reference/optim_adam.html" class="external-link">optim_adam</a></span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">records</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/lr_finder.html">lr_finder</a></span><span class="op">(</span></span>
<span>  object <span class="op">=</span> <span class="va">model</span>, </span>
<span>  data <span class="op">=</span> <span class="va">train_ds</span>, </span>
<span>  verbose <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  dataloader_options <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>batch_size <span class="op">=</span> <span class="fl">32</span><span class="op">)</span>,</span>
<span>  start_lr <span class="op">=</span> <span class="fl">1e-6</span>, <span class="co"># the smallest value that will be tried</span></span>
<span>  end_lr <span class="op">=</span> <span class="fl">1</span> <span class="co"># the largest value to be experimented with</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/str.html" class="external-link">str</a></span><span class="op">(</span><span class="va">records</span><span class="op">)</span></span>
<span><span class="co">#&gt; Classes 'lr_records' and 'data.frame':   100 obs. of  2 variables:</span></span>
<span><span class="co">#&gt;  $ lr  : num  1.15e-06 1.32e-06 1.51e-06 1.74e-06 2.00e-06 ...</span></span>
<span><span class="co">#&gt;  $ loss: num  2.31 2.3 2.29 2.3 2.31 ...</span></span></code></pre></div>
<p>The result is a data frame with the losses and the learning rate in
each step. You can use the built-in plot method to display the exact
results, along with a exponentially smoothed value of the loss.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">records</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu">ggplot2</span><span class="fu">::</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_cartesian.html" class="external-link">coord_cartesian</a></span><span class="op">(</span>ylim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="cn">NA</span>, <span class="fl">5</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p><img src="lr-finder_files/figure-html/unnamed-chunk-5-1.png" width="700"></p>
<p>We can see that with small learning rates the loss doesn’t decrease.
At some point the loss starts decreasing until it reaches a point where
it starts increasing and explodes.</p>
<p>And how do we choose the learning rate using this plot? Sylvain
Gugger asked the same question in this <a href="https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html" class="external-link">blog
post</a> and we are quoting his answer:</p>
<blockquote>
<p>Not the one corresponding to the minimum. Why? Well the learning rate
that corresponds to the minimum value is already a bit too high, since
we are at the edge between improving and getting all over the place. We
want to go one order of magnitude before, a value that’s still
aggressive (so that we train quickly) but still on the safe side from an
explosion.</p>
</blockquote>
<p>In the above example we would choose 1e-3 instead of 1e-2.</p>
  </main>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Daniel Falbel.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
