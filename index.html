<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Higher Level API for torch • luz</title>
<script src="deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="deps/headroom-0.11.0/headroom.min.js"></script><script src="deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="deps/search-1.0.0/fuse.min.js"></script><script src="deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="pkgdown.js"></script><meta property="og:title" content="Higher Level API for torch">
<meta name="description" content="A high level interface for torch providing utilities to reduce the the amount of code needed for common tasks, abstract away torch details and make the same code work on both the CPU and GPU. Its flexible enough to support expressing a large range of models. Its heavily inspired by fastai by Howard et al. (2020) &lt;doi:10.48550/arXiv.2002.04688&gt;, Keras by Chollet et al. (2015) and PyTorch Lightning by Falcon et al. (2019) &lt;doi:10.5281/zenodo.3828935&gt;.">
<meta property="og:description" content="A high level interface for torch providing utilities to reduce the the amount of code needed for common tasks, abstract away torch details and make the same code work on both the CPU and GPU. Its flexible enough to support expressing a large range of models. Its heavily inspired by fastai by Howard et al. (2020) &lt;doi:10.48550/arXiv.2002.04688&gt;, Keras by Chollet et al. (2015) and PyTorch Lightning by Falcon et al. (2019) &lt;doi:10.5281/zenodo.3828935&gt;.">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="index.html">luz</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.4.0.9002</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><h6 class="dropdown-header" data-toc-skip>Using luz</h6></li>
    <li><a class="dropdown-item" href="articles/get-started.html">Get started</a></li>
    <li><a class="dropdown-item" href="articles/custom-loop.html">Custom loops</a></li>
    <li><a class="dropdown-item" href="articles/accelerator.html">Accelerator API</a></li>
    <li><h6 class="dropdown-header" data-toc-skip>Guides</h6></li>
    <li><a class="dropdown-item" href="articles/lr-finder.html">Using the lr_finder</a></li>
    <li><a class="dropdown-item" href="articles/checkpoints.html">Checkpoints models</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="articles/examples/index.html">Examples</a></li>
<li class="nav-item"><a class="nav-link" href="reference/index.html">Reference</a></li>
<li class="nav-item"><a class="nav-link" href="news/index.html">Changelog</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/mlverse/luz/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-home">
<div class="row">
  <main id="main" class="col-md-9"><div class="section level1">
<div class="page-header"><h1 id="luz">luz<a class="anchor" aria-label="anchor" href="#luz"></a>
</h1></div>
<!-- badges: start -->

<p>Luz is a higher level API for torch providing abstractions to allow for much less verbose training loops.</p>
<p>This package is still under development.</p>
<p>It is heavily inspired by other higher level frameworks for deep learning, to cite a few:</p>
<ul>
<li><p><a href="https://docs.fast.ai/" class="external-link">FastAI</a>: we are heavily inspired by the FastAI library, especially the <code>Learner</code> object and the callbacks API.</p></li>
<li><p><a href="https://keras.io/" class="external-link">Keras</a>: We are also heavily inspired by Keras, especially callback names. The lightning module interface is similar to <code>compile</code>, too.</p></li>
<li><p><a href="https://lightning.ai/pages/open-source/" class="external-link">PyTorch Lightning</a>: The idea of the <code>luz_module</code> being a subclass of <code>nn_module</code> is inspired by the <strong><code>LightningModule</code></strong> object in lightning.</p></li>
<li><p><a href="https://huggingface.co/docs/accelerate/" class="external-link">HuggingFace Accelerate</a>: The internal device placement API is heavily inspired by Accelerate, but is much more modest in features. Currently only CPU and Single GPU are supported.</p></li>
</ul>
<div class="section level2">
<h2 id="installation">Installation<a class="anchor" aria-label="anchor" href="#installation"></a>
</h2>
<p>You can install the released version from CRAN with:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html" class="external-link">install.packages</a></span><span class="op">(</span><span class="st">"luz"</span><span class="op">)</span></span></code></pre></div>
<p>or the development version with:</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">remotes</span><span class="fu">::</span><span class="fu">install_github</span><span class="op">(</span><span class="st">"mlverse/luz"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="example">Example<a class="anchor" aria-label="anchor" href="#example"></a>
</h2>
<p>Luz lets you take your torch <code>nn_module</code> definition and <code>fit</code> it to a dataloader, while handling the boring parts like moving data between devices, updating the weights, showing progress bars and tracking metrics.</p>
<p>Here’s an example defining and training an Autoencoder for the MNIST dataset. We selected parts of the code to highlight luz functionality. You can find the full example code <a href="https://mlverse.github.io/luz/articles/examples/mnist-autoencoder.html">here</a>.</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">net</span> <span class="op">&lt;-</span> <span class="fu">nn_module</span><span class="op">(</span></span>
<span>  <span class="st">"Net"</span>,</span>
<span>  initialize <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">encoder</span> <span class="op">&lt;-</span> <span class="fu">nn_sequential</span><span class="op">(</span></span>
<span>      <span class="fu">nn_conv2d</span><span class="op">(</span><span class="fl">1</span>, <span class="fl">6</span>, kernel_size<span class="op">=</span><span class="fl">5</span><span class="op">)</span>,</span>
<span>      <span class="fu">nn_relu</span><span class="op">(</span><span class="op">)</span>,</span>
<span>      <span class="fu">nn_conv2d</span><span class="op">(</span><span class="fl">6</span>, <span class="fl">16</span>, kernel_size<span class="op">=</span><span class="fl">5</span><span class="op">)</span>,</span>
<span>      <span class="fu">nn_relu</span><span class="op">(</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span>    <span class="va">self</span><span class="op">$</span><span class="va">decoder</span> <span class="op">&lt;-</span> <span class="fu">nn_sequential</span><span class="op">(</span></span>
<span>      <span class="fu">nn_conv_transpose2d</span><span class="op">(</span><span class="fl">16</span>, <span class="fl">6</span>, kernel_size <span class="op">=</span> <span class="fl">5</span><span class="op">)</span>,</span>
<span>      <span class="fu">nn_relu</span><span class="op">(</span><span class="op">)</span>,</span>
<span>      <span class="fu">nn_conv_transpose2d</span><span class="op">(</span><span class="fl">6</span>, <span class="fl">1</span>, kernel_size <span class="op">=</span> <span class="fl">5</span><span class="op">)</span>,</span>
<span>      <span class="fu">nn_sigmoid</span><span class="op">(</span><span class="op">)</span></span>
<span>    <span class="op">)</span></span>
<span>  <span class="op">}</span>,</span>
<span>  forward <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">x</span> <span class="op"><a href="reference/pipe.html">%&gt;%</a></span></span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">encoder</span><span class="op">(</span><span class="op">)</span> <span class="op"><a href="reference/pipe.html">%&gt;%</a></span></span>
<span>      <span class="va">self</span><span class="op">$</span><span class="fu">decoder</span><span class="op">(</span><span class="op">)</span></span>
<span>  <span class="op">}</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>Now that we have defined the Autoencoder architecture using <code><a href="https://torch.mlverse.org/docs/reference/nn_module.html" class="external-link">torch::nn_module()</a></code>, we can fit it using luz:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">fitted</span> <span class="op">&lt;-</span> <span class="va">net</span> <span class="op"><a href="reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="reference/setup.html">setup</a></span><span class="op">(</span></span>
<span>    loss <span class="op">=</span> <span class="fu">nn_mse_loss</span><span class="op">(</span><span class="op">)</span>,</span>
<span>    optimizer <span class="op">=</span> <span class="va">optim_adam</span></span>
<span>  <span class="op">)</span> <span class="op"><a href="reference/pipe.html">%&gt;%</a></span></span>
<span>  <span class="fu"><a href="https://generics.r-lib.org/reference/fit.html" class="external-link">fit</a></span><span class="op">(</span><span class="va">train_dl</span>, epochs <span class="op">=</span> <span class="fl">1</span>, valid_data <span class="op">=</span> <span class="va">test_dl</span><span class="op">)</span></span></code></pre></div>
</div>
</div>
  </main><aside class="col-md-3"><div class="links">
<h2 data-toc-skip>Links</h2>
<ul class="list-unstyled">
<li><a href="https://cloud.r-project.org/package=luz" class="external-link">View on CRAN</a></li>
<li><a href="https://github.com/mlverse/luz/" class="external-link">Browse source code</a></li>
</ul>
</div>

<div class="license">
<h2 data-toc-skip>License</h2>
<ul class="list-unstyled">
<li><a href="LICENSE.html">Full license</a></li>
<li><small><a href="https://opensource.org/licenses/mit-license.php" class="external-link">MIT</a> + file <a href="LICENSE-text.html">LICENSE</a></small></li>
</ul>
</div>


<div class="citation">
<h2 data-toc-skip>Citation</h2>
<ul class="list-unstyled">
<li><a href="authors.html#citation">Citing luz</a></li>
</ul>
</div>

<div class="developers">
<h2 data-toc-skip>Developers</h2>
<ul class="list-unstyled">
<li>Daniel Falbel <br><small class="roles"> Author, maintainer, copyright holder </small>   </li>
<li><a href="authors.html">More about authors...</a></li>
</ul>
</div>

<div class="dev-status">
<h2 data-toc-skip>Dev status</h2>
<ul class="list-unstyled">
<li><a href="https://github.com/mlverse/luz/actions" class="external-link"><img src="https://github.com/mlverse/luz/workflows/R-CMD-check/badge.svg" alt="R-CMD-check"></a></li>
<li><a href="https://app.codecov.io/gh/mlverse/luz?branch=main" class="external-link"><img src="https://codecov.io/gh/mlverse/luz/branch/main/graph/badge.svg" alt="Codecov test coverage"></a></li>
<li><a href="https://discord.com/invite/s3D5cKhBkx" class="external-link"><img src="https://img.shields.io/discord/837019024499277855?logo=discord" alt="Discord"></a></li>
<li><a href="https://CRAN.R-project.org/package=luz" class="external-link"><img src="https://www.r-pkg.org/badges/version/luz" alt="CRAN status"></a></li>
<li><a href="https://cran.r-project.org/package=luz" class="external-link"><img src="https://cranlogs.r-pkg.org/badges/luz"></a></li>
</ul>
</div>

  </aside>
</div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Daniel Falbel.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
